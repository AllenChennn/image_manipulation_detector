{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Deep Learning Approach To Universal Image Manipulation Detection Using A New Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "from glob import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_square_grid(images):\n",
    "    \"\"\"\n",
    "    Save images as a square grid\n",
    "    :param images: Images to be used for the grid\n",
    "    :param mode: The mode to use for images\n",
    "    :return: Image of images in a square grid\n",
    "    \"\"\"\n",
    "    # Get maximum size for square grid of images\n",
    "    save_size = math.floor(np.sqrt(images.shape[0]))\n",
    "\n",
    "    # Scale to 0-255\n",
    "    images = (((images - images.min()) * 255) / (images.max() - images.min())).astype(np.uint8)\n",
    "\n",
    "    # Put images in a square arrangement\n",
    "    images_in_square = np.reshape(\n",
    "            images[:save_size*save_size],\n",
    "            (save_size, save_size, images.shape[1], images.shape[2]))\n",
    "    h = images.shape[1]\n",
    "    w = images.shape[2]\n",
    "    # Combine images to grid image\n",
    "    new_im = np.ones((save_size*h, save_size*w), dtype=np.uint8)\n",
    "    for col_i, col_images in enumerate(images_in_square):\n",
    "        for image_i, image in enumerate(col_images):\n",
    "            new_im[col_i * h: col_i * h + h, \n",
    "                   image_i * h: image_i * h + h] = image\n",
    "\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "IMAGE_CHANNEL = 1\n",
    "NUM_LABELS = 2\n",
    "\n",
    "CONV_RES_DEEP = 12\n",
    "CONV_RES_SIZE = 5\n",
    "\n",
    "CONV1_DEEP = 64\n",
    "CONV1_SIZE = 7\n",
    "\n",
    "CONV2_DEEP = 48\n",
    "CONV2_SIZE = 5\n",
    "\n",
    "FC_SIZE1 = 256\n",
    "FC_SIZE2 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data using a batch size 64\n",
    "# where input shape is (64, 227, 227, 1)\n",
    "def parser(record):\n",
    "    features = tf.parse_single_example(\n",
    "        record,\n",
    "        features={\n",
    "            \"image_raw\" : tf.FixedLenFeature([], tf.string),\n",
    "            \"label\" : tf.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    )\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "#     image.set_shape([256, 256])\n",
    "    image = tf.reshape(image, [256, 256, 1])\n",
    "    label = features['label']\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def preprocessing(image, label):\n",
    "    img = tf.image.resize_image_with_crop_or_pad(image, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # scale image to 0~1\n",
    "#     img = (((img - tf.reduce_min(img))) / (tf.reduce_max(img) - tf.reduce_min(img)))\n",
    "    img = img / 255\n",
    "    \n",
    "    ont_hot = tf.one_hot(label, depth=NUM_LABELS)\n",
    "#     label = tf.expand_dims(label , -1)\n",
    "    \n",
    "    return img, ont_hot\n",
    "\n",
    "def dataset(file, batch_size=32, \n",
    "            num_epochs=1, is_shuffle=False, shuffle_buffer=10000, \n",
    "            preprocess=preprocessing):\n",
    "#     if train_file is None:\n",
    "#         train_file = \"mini_dataset/my_dataset/train.tfrecords\"\n",
    "#     if test_file is None:\n",
    "#         test_file = \"mini_dataset/my_dataset/test.tfrecords\"\n",
    "    input_file = tf.train.match_filenames_once(file)\n",
    "    dataset = tf.data.TFRecordDataset(input_file)\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.map(preprocess)\n",
    "    if is_shuffle:\n",
    "        dataset = dataset.shuffle(shuffle_buffer)\n",
    "    \n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset and preprocessing\n",
    "data = dataset(\"dataset/tfrecords/MF_clf_train.tfrecords-*\")\n",
    "ite = data.make_initializable_iterator()\n",
    "img_batch, label_batch = ite.get_next()\n",
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(),\n",
    "              tf.local_variables_initializer()])\n",
    "    sess.run(ite.initializer)\n",
    "    for i in range(2):\n",
    "        image, lab = sess.run([img_batch, label_batch])\n",
    "        print(\"    \", image.shape, image.dtype)\n",
    "        print(\"    \", lab.shape, lab.dtype)\n",
    "        \n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(images_square_grid(image), cmap=\"gray\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_placeholder():\n",
    "    input_placeholder = tf.placeholder(dtype=tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name='input_placeholder')\n",
    "    \n",
    "    labels_placeholder = tf.placeholder(dtype=tf.float32, shape=[None, NUM_LABELS], name='label_placeholder')\n",
    "    \n",
    "    dropout_placeholder = tf.placeholder(dtype=tf.float32, shape=[], name='dropout_placeholder')\n",
    "    \n",
    "    return input_placeholder, labels_placeholder, dropout_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraint_weights(weights):\n",
    "#     assert weights.shape == (CONV_RES_SIZE, CONV_RES_SIZE, IMAGE_CHANNEL, CONV_RES_DEEP)\n",
    "    mid_inx = CONV_RES_SIZE // 2\n",
    "    weights[mid_inx, mid_inx, :, :] = 0\n",
    "    weights = weights / np.sum(weights, axis=(0, 1))\n",
    "    weights[mid_inx, mid_inx, :, :] = -1\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(shape, name=\"weights\"):\n",
    "    return tf.Variable(tf.truncated_normal(shape=shape, stddev=0.1), name=name)\n",
    "\n",
    "def get_bias(shape, name=\"bias\"):\n",
    "    return tf.Variable(tf.constant(0.01, shape=shape), dtype=tf.float32, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn(input_tensor, labels, dropout):\n",
    "    with tf.variable_scope('layer1_conv_res'):\n",
    "        conv_res_weights = get_weights([CONV_RES_SIZE, CONV_RES_SIZE, IMAGE_CHANNEL, CONV_RES_DEEP])\n",
    "        conv_res_bias = get_bias([CONV_RES_DEEP, ])\n",
    "        \n",
    "        conv = tf.nn.conv2d(input_tensor, conv_res_weights, strides=[1,1,1,1], padding='VALID')\n",
    "        layer1 = tf.nn.bias_add(conv, conv_res_bias)\n",
    "        \n",
    "        print(\"conv1\", layer1.get_shape().as_list())\n",
    "    # BATHCH_SIZE, 223, 223, 12\n",
    "    with tf.variable_scope('layer2_conv1'):\n",
    "        conv1_wights = get_weights([CONV1_SIZE, CONV1_SIZE, CONV_RES_DEEP, CONV1_DEEP])\n",
    "        conv1_bias = get_bias([CONV1_DEEP, ])\n",
    "        \n",
    "        conv1 = tf.nn.conv2d(layer1, conv1_wights, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        conv1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "        conv1 = tf.nn.lrn(conv1, depth_radius=5, bias=2, alpha=1e-4, beta=.75)\n",
    "        layer2 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        print(\"conv2\", layer2.get_shape().as_list())\n",
    "    # batch_size, 56, 56, 64\n",
    "    with tf.variable_scope('layer3_conv2'):\n",
    "        conv2_wights = get_weights([CONV2_SIZE, CONV2_SIZE, CONV1_DEEP, CONV2_DEEP])\n",
    "        conv2_bias = get_bias([CONV2_DEEP, ])\n",
    "        \n",
    "        conv2 = tf.nn.conv2d(layer2, conv2_wights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        conv2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_bias))\n",
    "        conv2 = tf.nn.lrn(conv2, depth_radius=5, bias=2, alpha=1e-4, beta=.75)\n",
    "        layer3 = tf.nn.max_pool(conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        print(\"conv3\", layer3.get_shape().as_list())\n",
    "    # batch_size, 28, 28, 48\n",
    "    # reshape\n",
    "    layer3_shape = layer3.get_shape().as_list()\n",
    "    nodes = layer3_shape[1] * layer3_shape[2] * layer3_shape[3]\n",
    "    layer3_flatten = tf.reshape(layer3, [-1, nodes])\n",
    "#     print(layer3_shape)\n",
    "    \n",
    "    with tf.variable_scope(\"layer4_fc1\"):\n",
    "        fc1_weights = get_weights([nodes, FC_SIZE1])\n",
    "        fc1_bias = get_bias([FC_SIZE1])\n",
    "        fc1 = tf.nn.relu(tf.matmul(layer3_flatten, fc1_weights) + fc1_bias)\n",
    "        layer4 = tf.nn.dropout(fc1, dropout)\n",
    "        \n",
    "    with tf.variable_scope(\"layer5_fc2\"):\n",
    "        fc2_weights = get_weights([FC_SIZE1, FC_SIZE2])\n",
    "        fc2_bias = get_bias([FC_SIZE2])\n",
    "        fc2 = tf.nn.relu(tf.matmul(layer4, fc2_weights) + fc2_bias)\n",
    "        layer5 = tf.nn.dropout(fc2, dropout)\n",
    "    \n",
    "    with tf.variable_scope(\"layer6_softmax\"):\n",
    "        softmax_weights = get_weights([FC_SIZE2, NUM_LABELS])\n",
    "        softmax_bias = get_bias([NUM_LABELS, ])\n",
    "        logits = tf.matmul(layer5, softmax_weights) + softmax_bias\n",
    "        pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        correct = tf.equal(tf.argmax(pred, 1), tf.argmax(labels, 1))\n",
    "        acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
    "        \n",
    "#         tf.summary.scalar('loss',loss)\n",
    "#         tf.summary.scalar('acc',acc)\n",
    "    return loss, acc, conv_res_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trian(PRINT_LOSS_EVERY_ITE=500, PRINT_ACC_EVERY_ITE=1000):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    train_dataset = dataset(\"tfrecords/MF_clf_train.tfrecords-*\", \n",
    "                            batch_size=64, \n",
    "                            num_epochs=50, \n",
    "                            is_shuffle=False)\n",
    "    test_dataset = dataset(\"tfrecords/MF_clf_test.tfrecords\", \n",
    "                            batch_size=100, \n",
    "                            num_epochs=1)\n",
    "    iterator = train_dataset.make_initializable_iterator()\n",
    "    test_iterator = test_dataset.make_initializable_iterator()\n",
    "    \n",
    "    image_batch, label_batch = iterator.get_next()\n",
    "    test_image_batch, test_label_batch = test_iterator.get_next()\n",
    "    \n",
    "    input_placeholder, labels_placeholder, dropout_placeholder = get_placeholder()\n",
    "    loss, acc, weights= build_nn(input_placeholder, labels_placeholder, dropout_placeholder)\n",
    "    \n",
    "#     global_step = tf.Variable(0, trainable=False)\n",
    "#     lr = tf.train.exponential_decay(1e-4, global_step, 1000, 0.95)\n",
    "#     train = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss, global_step=global_step)\n",
    "#     train = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9).minimize(loss)\n",
    "    train = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_acces = []\n",
    "    test_acces = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "        sess.run([iterator.initializer, test_iterator.initializer])\n",
    "        \n",
    "        #################### test data ####################\n",
    "        dev_imgs, dev_labs = [], []\n",
    "        while True:\n",
    "            try:\n",
    "                b_imgs, b_labs = sess.run([test_image_batch, test_label_batch])\n",
    "                dev_imgs.append(b_imgs)\n",
    "                dev_labs.append(b_labs)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n",
    "        dev_imgs = np.concatenate(dev_imgs)\n",
    "        dev_labs = np.concatenate(dev_labs)\n",
    "        ###################################################\n",
    "        \n",
    "        num_iterat = 1\n",
    "        while True:\n",
    "            try:\n",
    "                _weights = sess.run(weights)\n",
    "                weights.load(constraint_weights(_weights), sess)\n",
    "                \n",
    "                _image_batch, _label_batch = sess.run([image_batch, label_batch])\n",
    "                _, _loss, _acc = sess.run([train, loss, acc], feed_dict={\n",
    "                    input_placeholder: _image_batch,\n",
    "                    labels_placeholder: _label_batch,\n",
    "                    dropout_placeholder: 0.5 })\n",
    "                num_iterat += 1\n",
    "                \n",
    "                train_acces.append(_acc)\n",
    "                train_losses.append(_loss)\n",
    "                \n",
    "                if num_iterat > 20000:\n",
    "                    break\n",
    "\n",
    "                \n",
    "                sys.stdout.write(\"\\r ite {:>3} train loss:{:>6.2f}  train acc:{:.4f}\".format(num_iterat, _loss, _acc))\n",
    "                if num_iterat % PRINT_LOSS_EVERY_ITE == 0:\n",
    "                    print(\"\")\n",
    "                    \n",
    "    \n",
    "                if num_iterat % PRINT_ACC_EVERY_ITE == 0:\n",
    "                    _loss, _acc = sess.run([loss, acc], feed_dict={\n",
    "                    input_placeholder : dev_imgs,\n",
    "                    labels_placeholder : dev_labs,\n",
    "                    dropout_placeholder : 1})\n",
    "\n",
    "                    test_losses.append(_loss)\n",
    "                    test_acces.append(_acc)\n",
    "                    \n",
    "                    print(\"\\ntest loss = %.5f  test acc = %.6f\" % (_loss, _acc) )\n",
    "                    \n",
    "                    if _acc > 0.99:\n",
    "                        saver.save(sess, \"save/MF_clf_model.ckpt\")\n",
    "                        break\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                _weights = sess.run(weights)\n",
    "                weights.load(constraint_weights(_weights), sess)\n",
    "                print(\"training end\")\n",
    "                \n",
    "                saver.save(sess, \"save/MF_clf_model.ckpt\")\n",
    "                break\n",
    "                \n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(221)\n",
    "    plt.plot(train_losses, c='b')\n",
    "    plt.subplot(222)\n",
    "    plt.plot(train_acces, c='b')\n",
    "    plt.subplot(223)\n",
    "    plt.plot(test_losses, c='r')\n",
    "    plt.subplot(224)\n",
    "    plt.plot(test_acces, c='r')\n",
    "    plt.show()\n",
    "\n",
    "# trian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载训练好的模型进行结果验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "\n",
    "input_placeholder, labels_placeholder, dropout_placeholder = get_placeholder()\n",
    "loss, acc, weights= build_nn(input_placeholder, labels_placeholder, dropout_placeholder)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "saver.restore(sess, \"save/MF_clf_model.ckpt\")\n",
    "\n",
    "_weights = sess.run(weights)\n",
    "weights.load(constraint_weights(_weights), sess)\n",
    "pred = tf.get_default_graph().get_tensor_by_name(\"layer6_softmax/Softmax:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split64(gray_img):\n",
    "    height, width = gray_img.shape\n",
    "    # [num_raws, num_cols] are subimage numbers on vertical or horizontal direction\n",
    "    num_raws, num_cols = height//64, width//64\n",
    "    start_raws, start_cols = height%64//2, width%64//2\n",
    "    sub_imgs = []\n",
    "    indexes = [(i, j) for i in range(num_raws) for j in range(num_cols)]\n",
    "    for i, j in indexes:\n",
    "        x, y = start_cols + j * 64, start_raws + i * 64\n",
    "        sub_img = gray_img[y:y+64, x:x+64]\n",
    "        sub_imgs.append(sub_img)\n",
    "    return np.array(sub_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在UCID小分辨率图片上测试效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "a_lst = []\n",
    "for f in glob(\"dataset/ucid/*.tif\"):\n",
    "    try:\n",
    "        g = cv2.imread(f)[:,:,1]\n",
    "        imgs = split64(g)\n",
    "        p_imgs = np.array([cv2.medianBlur(i, 5) for i in imgs])\n",
    "\n",
    "        x = np.concatenate([imgs, p_imgs])\n",
    "        x = x.reshape([-1, 64, 64, 1])\n",
    "        x = x / 255\n",
    "        y = np.zeros([x.shape[0]])\n",
    "        y[x.shape[0]//2:] = 1\n",
    "        \n",
    "        y = pd.get_dummies(y).values\n",
    "\n",
    "        _a = sess.run(acc, feed_dict={\n",
    "            input_placeholder: x, \n",
    "            labels_placeholder: y, \n",
    "            dropout_placeholder: 1.0\n",
    "        })\n",
    "        a_lst.append(_a)\n",
    "    except:\n",
    "        continue\n",
    "print(\"average accurracy on UCID is %.2f%%\" % (np.array(a_lst).mean()*100) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lst = []\n",
    "for f in glob(\"dataset/ucid/*.tif\"):\n",
    "    try:\n",
    "        g = cv2.imread(f)[:,:,1]\n",
    "        imgs = split64(g)\n",
    "        x = imgs.reshape([-1, 64, 64, 1])\n",
    "        x = x / 255\n",
    "        y = np.array([[1, 0] for _ in range(x.shape[0])])\n",
    "\n",
    "        _a = sess.run(acc, feed_dict={\n",
    "            input_placeholder: x, \n",
    "            labels_placeholder: y, \n",
    "            dropout_placeholder: 1.0\n",
    "        })\n",
    "        a_lst.append(_a)\n",
    "    except:\n",
    "        continue\n",
    "print(\"average error on UCID is %.2f%%\" % (100-np.array(a_lst).mean()*100) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This means an image is recongnize as altered one if it has 7.55% or more blocks(64 by 64) diagnosised as positive , in which 7.55% is a threshold computed on UCID dataset.__  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人物照片上测试分类准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = cv2.imread(\"./yy.jpg\")[:,:,1]\n",
    "imgs = split64(g)\n",
    "p_imgs = np.array([cv2.medianBlur(i, 5) for i in imgs])\n",
    "\n",
    "x = np.concatenate([imgs, p_imgs])\n",
    "x = x.reshape([-1, 64, 64, 1])\n",
    "x = x / 255\n",
    "y = np.zeros([x.shape[0]])\n",
    "y[x.shape[0]//2:] = 1\n",
    "import pandas as pd\n",
    "y = pd.get_dummies(y).values\n",
    "\n",
    "a = sess.run(acc, feed_dict={\n",
    "    input_placeholder: x, \n",
    "    labels_placeholder: y, \n",
    "    dropout_placeholder: 1.0\n",
    "})\n",
    "print(\"acc %.2f%% over %d blocks\" % (a*100, x.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测修过图的照片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.imread(\"me.jpg\", cv2.IMREAD_ANYCOLOR)[:,:,1]\n",
    "\n",
    "height, width = gray_img.shape\n",
    "# [num_raws, num_cols] are subimage numbers on vertical or horizontal direction\n",
    "num_raws, num_cols = height//64, width//64\n",
    "start_raws, start_cols = height%64//2, width%64//2\n",
    "img_boxes = np.copy(gray_img)  # for test perpose\n",
    "\n",
    "indexes = [(i, j) for i in range(num_raws) for j in range(num_cols)]\n",
    "\n",
    "for i, j in indexes:\n",
    "    x, y = start_cols + j * 64, start_raws + i * 64\n",
    "    sub_img = gray_img[y:y+64, x:x+64]\n",
    "    p = sess.run(pred, feed_dict={input_placeholder: sub_img.reshape([1,64,64,1])/255, \n",
    "                                    dropout_placeholder:1.0})\n",
    "    if np.argmax(p, 1) == 1:\n",
    "        cv2.rectangle(img_boxes, (x, y), (x+64, y+64), (0, 255, 0), 5)\n",
    "    \n",
    "plt.figure(figsize=(9, 16))\n",
    "plt.imshow(img_boxes, cmap=\"gray\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原图 vs PS后图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检测函数\n",
    "def detect(file):\n",
    "    gray_img = cv2.imread(file, cv2.IMREAD_ANYCOLOR)[:,:,1]\n",
    "    height, width = gray_img.shape\n",
    "    # [num_raws, num_cols] are subimage numbers on vertical or horizontal direction\n",
    "    num_raws, num_cols = height//64, width//64\n",
    "    start_raws, start_cols = height%64//2, width%64//2\n",
    "    sub_imgs = []\n",
    "    img_boxes = np.copy(gray_img)  # for test perpose\n",
    "    indexes = [(i, j) for i in range(num_raws) for j in range(num_cols)]\n",
    "    for i, j in indexes:\n",
    "        x, y = start_cols + j * 64, start_raws + i * 64\n",
    "        sub_img = gray_img[y:y+64, x:x+64]\n",
    "        sub_imgs.append(sub_img)\n",
    "        p = sess.run(pred, feed_dict={input_placeholder: sub_img.reshape([1,64,64,1])/255, \n",
    "                                        dropout_placeholder:1.0})\n",
    "        if np.argmax(p, 1) == 1:\n",
    "            cv2.rectangle(img_boxes, (x, y), (x+64, y+64), (0, 255, 0), 5)\n",
    "    return img_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = detect('tt.jpg')\n",
    "r2 = detect('tt-ps.jpg')\n",
    "\n",
    "plt.figure(figsize=(18, 18))\n",
    "plt.subplot(211)\n",
    "plt.imshow(r1, cmap='gray')\n",
    "plt.title('unchange img')\n",
    "plt.subplot(212)\n",
    "plt.imshow(r2, cmap='gray')\n",
    "plt.title('after PS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## residual层的特征可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tf.get_default_graph().get_tensor_by_name('layer1_conv_res/BiasAdd:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"dataset/ucid/ucid00004.tif\"\n",
    "\n",
    "g = cv2.imread(f)[:,:,1]\n",
    "imgs = split64(g)\n",
    "x = np.array([cv2.medianBlur(i, 5) for i in imgs])\n",
    "x = x.reshape([-1, 64, 64, 1])\n",
    "x = x / 255\n",
    "\n",
    "res_o = sess.run(res, feed_dict={input_placeholder: x})\n",
    "res_imgs = [[x[i,:,:,0]]+[res_o[i, :,:, j] for j in range(12)] for i in range(5)]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=12, sharex=True, sharey=True, figsize=(12*1.5,5*1.5))\n",
    "\n",
    "for images, row in zip(res_imgs, axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img, cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)\n",
    "print(\"residual output among several changed images, x = channels, y = inputs\")\n",
    "plt.show()\n",
    "\n",
    "print(\"residual output among several original images\")\n",
    "g = cv2.imread(f)[:,:,1]\n",
    "imgs = split64(g)\n",
    "x = imgs.reshape([-1, 64, 64, 1])\n",
    "x = x / 255\n",
    "\n",
    "res_o = sess.run(res, feed_dict={input_placeholder: x})\n",
    "res_imgs = [[x[i,:,:,0]]+[res_o[i, :,:, j] for j in range(12)] for i in range(5)]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=12, sharex=True, sharey=True, figsize=(12*1.5,5*1.5))\n",
    "\n",
    "for images, row in zip(res_imgs, axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img, cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test on a small PS image dataset find in Baidu Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for f in glob(\"test_img/*.*\"):\n",
    "#     try:\n",
    "    g = cv2.imread(f)[:,:,1]\n",
    "    imgs = split64(g)\n",
    "    x = imgs.reshape([-1, 64, 64, 1])\n",
    "    x = x / 255\n",
    "\n",
    "    _p = sess.run(pred, feed_dict={\n",
    "        input_placeholder: x, \n",
    "        dropout_placeholder: 1.0\n",
    "    })\n",
    "    score = np.argmax(_p, 1).mean()\n",
    "    results.append(score)\n",
    "#     if score > 0.01:\n",
    "    r1 = detect(f)\n",
    "    plt.imshow(r1, cmap='gray')\n",
    "    plt.show()\n",
    "#     except:\n",
    "#         continue\n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

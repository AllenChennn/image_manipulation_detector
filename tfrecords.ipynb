{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_256(gray_img):\n",
    "    height, width = gray_img.shape\n",
    "    num_raws, num_cols = height//256, width//256\n",
    "    start_raws, start_cols = height%256//2, width%256//2\n",
    "    \n",
    "    sub_imgs = []\n",
    "        \n",
    "    indexes = [(i, j) for i in range(num_raws) for j in range(num_cols)]\n",
    "    \n",
    "    for i, j in indexes:\n",
    "        x, y = start_cols + j * 256, start_raws + i * 256\n",
    "        sub_img = gray_img[y:y+256, x:x+256]\n",
    "        sub_imgs.append(sub_img)\n",
    "    return np.array(sub_imgs)\n",
    "\n",
    "\n",
    "def images_square_grid(images):\n",
    "    \"\"\"\n",
    "    Save images as a square grid\n",
    "    :param images: Images to be used for the grid\n",
    "    :param mode: The mode to use for images\n",
    "    :return: Image of images in a square grid\n",
    "    \"\"\"\n",
    "    # Get maximum size for square grid of images\n",
    "    save_size = math.floor(np.sqrt(images.shape[0]))\n",
    "\n",
    "    images = (((images - images.min()) * 255) / (images.max() - images.min())).astype(np.uint8)\n",
    "\n",
    "    images_in_square = np.reshape(\n",
    "            images[:save_size*save_size],\n",
    "            (save_size, save_size, images.shape[1], images.shape[2]))\n",
    "\n",
    "    # Combine images to grid image\n",
    "    new_im = np.ones((save_size*256, save_size*256), dtype=np.uint8)\n",
    "    for col_i, col_images in enumerate(images_in_square):\n",
    "        for image_i, image in enumerate(col_images):\n",
    "            new_im[col_i * 256: col_i * 256 + 256, \n",
    "                   image_i * 256: image_i * 256 + 256] = image\n",
    "\n",
    "    return new_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file_lst = glob(\"dataset/ddimgdb/*\")\n",
    "np.random.shuffle(img_file_lst)\n",
    "print(\"    %d items\" % len(img_file_lst))\n",
    "print(\"    show top 5 items\")\n",
    "print(\"\\n\".join(img_file_lst[:5]))\n",
    "\n",
    "output_path= \"dataset/db256_1\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)\n",
    "\n",
    "all_files = len(img_file_lst)\n",
    "\n",
    "for i_file, file in tqdm(enumerate(img_file_lst), total=all_files):\n",
    "    name = file.split(\"\\\\\")[1].split(\".\")[0]\n",
    "                       \n",
    "    img = cv2.imread(file, cv2.IMREAD_COLOR)\n",
    "    gray_img = cv2.split(img)[1]   # r,g,b split\n",
    "    \n",
    "    sub_imgs = split_256(gray_img)\n",
    "    nums_imgs = len(sub_imgs)\n",
    "    \n",
    "    for i, img in enumerate(sub_imgs):\n",
    "        cv2.imwrite(\"%s/%s-%.3d-of-%.3d.jpg\" % (output_path, name, i+1, nums_imgs), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def __bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_file = files[:50000]\n",
    "p_file = [\"TAG:positive\" + each for each in n_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = n_file + p_file\n",
    "np.random.shuffle(train_file)\n",
    "\n",
    "test_file = files[-800:] + [\"TAG:positive\"+each for each in files[-800:]]\n",
    "np.random.shuffle(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train size:\", len(train_file), \"  test size:\", len(test_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_per_shard = 5000\n",
    "num_shards = len(train_file) // instances_per_shard\n",
    "\n",
    "for i in range(num_shards):\n",
    "    \n",
    "    tfrecord = \"tfrecords/MF_clf_train.tfrecords-%.2d-of-%.2d\" % (i+1, num_shards)\n",
    "    writer = tf.python_io.TFRecordWriter(tfrecord)\n",
    "    \n",
    "    s_i = instances_per_shard * i\n",
    "    e_i = s_i + instances_per_shard\n",
    "    for file in tqdm( train_file[s_i : e_i] ):\n",
    "        if file.startswith(\"TAG:positive\"):\n",
    "            img = cv2.imread(file[12:], cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.medianBlur(img, ksize=5)\n",
    "\n",
    "            label = 1\n",
    "        else:\n",
    "            img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "            label = 0\n",
    "        \n",
    "        image_raw = img.reshape([256 * 256])\n",
    "        image_raw = image_raw.tostring()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image_raw':__bytes_feature(image_raw),\n",
    "            'label':__int64_feature(label),\n",
    "            'path':__bytes_feature( bytes(file, encoding='utf-8') ) \n",
    "        }))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_per_shard = 5000\n",
    "num_shards = len(test_file) // instances_per_shard\n",
    "\n",
    "tfrecord = \"tfrecords/MF_clf_test.tfrecords\"\n",
    "writer = tf.python_io.TFRecordWriter(tfrecord)\n",
    "\n",
    "for file in tqdm( test_file ):\n",
    "    if file.startswith(\"TAG:positive\"):\n",
    "        img = cv2.imread(file[12:], cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.medianBlur(img, ksize=5)\n",
    "\n",
    "        label = 1\n",
    "    else:\n",
    "        img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        label = 0\n",
    "\n",
    "    image_raw = img.reshape([256 * 256])\n",
    "    image_raw = image_raw.tostring()\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image_raw':__bytes_feature(image_raw),\n",
    "        'label':__int64_feature(label),\n",
    "        'path':__bytes_feature( bytes(file, encoding='utf-8') ) \n",
    "    }))\n",
    "    writer.write(example.SerializeToString())\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
